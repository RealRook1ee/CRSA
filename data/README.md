# CRSA Dataset Repository

This repository contains the official release of the **CRSA (Context-Rich Semantic Annotation)** dataset and its associated training subsets for both:

- **Automatic Annotation Model Training**  
- **Dialogue Response Generation Model Training**

CRSA is a Chinese task-oriented dialogue dataset constructed under a structured Wizard-of-Oz framework. It features multi-source construction, multi-level annotations, and fine-grained behavior control signals to support the development of controllable, semantically rich dialogue systems.

---

## ğŸ“¦ Dataset Structure

The repository contains the following components:

CRSA-Dataset/
â”œâ”€â”€ raw_corpus/ # Original dialogues before annotation
â”‚ â”œâ”€â”€ real_user_dialogues.json # From real service logs
â”‚ â”œâ”€â”€ simulated_dialogues.json # From crowd-annotated and LLM-enhanced simulation
â”‚ â””â”€â”€ README.md # Description of data sources and cleaning procedures
â”‚
â”œâ”€â”€ annotated_for_annotation_model/ # Used to train the automatic annotator
â”‚ â”œâ”€â”€ train.json # Instruction â†’ structured annotation
â”‚ â”œâ”€â”€ valid.json
â”‚ â”œâ”€â”€ test.json
â”‚ â””â”€â”€ sample_instruction_format.md # Instruction-format annotation example
â”‚
â”œâ”€â”€ annotated_for_dialogue_system/ # Used to train the dialogue generation model
â”‚ â”œâ”€â”€ train.json # Instruction â†’ system response
â”‚ â”œâ”€â”€ valid.json
â”‚ â”œâ”€â”€ test.json
â”‚ â””â”€â”€ prompt_design.md # Description of input structure (T, H, M, K)
â”‚
â”œâ”€â”€ schema/ # Slot schema and annotation conventions
â”‚ â”œâ”€â”€ slot_definitions.md
â”‚ â”œâ”€â”€ user_anomaly_types.md
â”‚ â””â”€â”€ annotation_guidelines.pdf
â”‚
â””â”€â”€ LICENSE # License: CC BY 4.0

---

## ğŸ” Dataset Overview

| Component                            | Description                                                                 |
|-------------------------------------|-----------------------------------------------------------------------------|
| `raw_corpus/`                       | Contains original dialogues collected from three sources: service logs, crowd simulation, and LLM generation |
| `annotated_for_annotation_model/`  | Instruction-tuning dataset for training Baichuan2-based structure prediction model |
| `annotated_for_dialogue_system/`   | Structured-response generation dataset for training a dialogue system |
| `schema/`                           | Defines the slot-value schema, user behavior types, and annotation protocols |

---

## ğŸ§  Annotation Format (Multi-Level)

All annotated dialogues follow the **CRSA structured JSON format**, which includes three levels:

- `Context`: Dialogue history segmented by task stage, with accumulated slot values
- `Dialogue`: Current user-system interaction with intent and anomaly analysis
- `Slots`: Global slot summary extracted from the full session

Each turn is manually or automatically annotated with:

- Dialogue phase (e.g., basic_information, ticket_selection)
- System dialogue act
- User anomaly type (if any)
- Semantic slot-value changes
- Key control signals for generation (e.g., $K_a$, $K_s$)

---

## ğŸ“š Usage

### For Automatic Annotation Training

Use `annotated_for_annotation_model/*.json` with LLaMA-Factory or instruction-tuned models.

### For Dialogue System Training

Use `annotated_for_dialogue_system/*.json` with LLaMA-Factory or instruction-tuned models.


